data        <- textFile(sc, ~/data1.txt)
data        <- textFile(sc, "~/data1.txt")
sc <- sparkR.init(args[[1]], "RGSEA")
sc <- sparkR.init(local[8], "RGSEA")
sc <- sparkR.init("local[8]", "RGSEA")
geneSetList <- textFile(sc, "geneSetGenes1.txt"
)
geneNames <- readLines("~/symbols1.txt")
groups <- c(rep(1,200),rep(0,252))
num.iterations <- 2
data <- flatMap(data, function(x){
as.numeric(strsplit(x, "\t")[[1]])
})
class(data)
data        <- textFile(sc, "~/data1.txt")
class(data)
data <- flatMap(data, function(x){
as.numeric(strsplit(x, "\t")[[1]])
})
class(data)
collected.data <- collect(data)
class(collected.data)
collected.data <- collect(data)
data        <- textFile(sc, "~/data1.txt")
data        <- textFile(sc, "~/data1.txt")
library(SparkR)
args <- list("local[4]","~/data1.txt","~/geneSetGenes1.txt")
if (length(args) != 3) {
print("Usage: diffexpr <master> <gene expression file> <gene set file>")
q("no")
}
# Initialize Spark context
sc <- sparkR.init(args[[1]], "RGSEA")
data        <- textFile(sc, args[[2]])                                ## For SparkR running
geneSetList <- textFile(sc, args[[3]])                                ## For SparkR running
data        <- textFile(sc, args[[2]])                                ## For SparkR running
size(data)
geneNames <- readLines("~/symbols1.txt")
groups <- c(rep(1,200),rep(0,252))
num.iterations <- 2
data <- flatMap(data, function(x){
list(as.numeric(strsplit(x, "\t")[[1]]))
})
groupsPerm <- cbind(groups, replicate(nperm, sample(groups))) # first column is observed groups, all others are randomized
pVals <- lapply(data, function(value) {
# Can we improve this so that it is known that the data passed is float array?
# This step seems not ideal
#     expr.data <- as.numeric(strsplit(value, "\t")[[1]])
print(value)
apply(groupsPerm, 2, function(grp){
t.test(value[grp==1],value[grp==0])$p.value
})
})
?lapply.RDD
data        <- textFile(sc, args[[2]])                                ## For SparkR running
data <- flatMap(data, function(x){
as.numeric(strsplit(x, "\t")[[1]])
})
length(data)
as.character(100)
save("~/floatvec.rdata",rnorm(10000))
?save
save(rnorm(10000),"~/floatvec.rdata")
floatVec <- rnorm(10000)
save(floatVec,file="~/floatvec.rdata")
floatVec <- as.character(rnorm(10000))
save(floatVec,file="~/charvec.rdata")
?parallelize
parallelize(matrix(rnorm(20),nrow=4))
parallelize(sc,matrix(rnorm(20),nrow=4))
matrix(rnorm(20),nrow=4)
parallelize(sc,matrix(rnorm(20),nrow=4),4)
rdd <- parallelize(sc,matrix(rnorm(20),nrow=4),4)
rdd <- parallelize(sc,matrix(rnorm(20),nrow=4),5)
rdd <- parallelize(sc,1:5,5)
rdd <- parallelize(sc, 1:10, 2)
sc <- sparkR.init()
rdd <- parallelize(sc, 1:10, 2)
rdd
length(rdd)
browseVignettes("GSEABase")
source("http://bioconductor.org/biocLite.R")
biocLite("GSEABase")
source("http://bioconductor.org/biocLite.R")
biocLite("GSEABase")
install.packages("knitr")
source("http://bioconductor.org/biocLite.R")
biocLite("PANDA")
source("http://bioconductor.org/biocLite.R")
biocLite("PANDAasdfafafqweff")
source("http://bioconductor.org/biocLite.R")
biocLite("PANDA")
source("http://bioconductor.org/biocLite.R")
biocLite("PANDA")
library(PANDA)
?PANDA
browseVignettes(package = "PANDA")
setRepositories()
browseVignettes("betr")
biocLite("betr")
browseVignettes("betr")
browseVignettes("sparkR")
browseVignettes("SparkR")
browseVignettes("knitr")
biocLite("limma")
browseVignettes("limma")
limmaUserGuide()
limmaUsersGuide()
library(limma)
limmaUsersGuide()
biocLite("attract")
biocLite("attract")
source("http://bioconductor.org/biocLite.R")
biocLite("attract")
library("attract")
biocLite("sam")
biocLite("SAM")
library(SAM)
browseVignettes("SAM")
biocLite("AnnotationDbi")
library("AnnotationDbi")
browseVignettes("AnnotationDbi")
5+6
browseVignettes("betr")
install.packages("~/gd/Harvard/Research/R_Packages/PANDA_0.4.tar.gz", repos = NULL, type = "source")
library(PANDA)
data(yeast)
class(yeast)
names(yeast)
res <- panda(yeast$motif, yeast$exp.sr)
install.packages("igraph")
example(panda)
?topedges
install.packages("BiocCheck")
library(BiocCheck)
install_github('dschlauch/pandaR')
library(devtools)
install_github('dschlauch/pandaR')
?install.package
?install.packages
?install.packages('devtools')
install.packages('devtools')
library(BiocCheck)
BiocCheck('./')
BiocCheck('./gd/Harvard/Research/R_Packages/pandaR')
browseVignettes(pandaR)
browseVignettes('pandaR')
library('pandaR')
browseVignettes('pandaR')
library(BiocCheck)
?BiocCheck
BiocCheck('~/gd/Harvard/Research/R_Packages/pandaR')
A <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
A
solve(A)
B <- matrix(c(3,-1,-1,-1,3,-1,-1,-1,3),nrow=3)
B
A%*%B
dist(A)
c(A)
sqrt(sum(c(A)^2)
)
sqrt(sum(c(A)^2))
c(A)^2
sqrt(sum(c(solve(A))^2))
solve(A)
sqrt(sum(c(A)^2))*sqrt(sum(c(solve(A))^2))
?kappa
kappa(A)
?kappa
kappa
A <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
sqrt(sum(c(A)^2))*sqrt(sum(c(solve(A))^2))
A
A%*%solve(A)
solve(A)
norm(A)
norm(solve(A))
kappa(A)
norm(diag(10))
norm(solve(A),type="F")
norm(A,type="F")*norm(solve(A),type="F")
A <- matrix(c(168,113,113,76),nrow=2)
A%*%solve(A)
sqrt(sum(c(A)^2))*sqrt(sum(c(solve(A))^2))
norm(A,type="F")*norm(solve(A),type="F")
solve(A)
norm(A,type="F")
norm(solve(A),type="F")
?kappa
kappa(A)
kappa(A,exact=TRUE)
A <- matrix(c(2,1,1,1,2,1,1,1,2),nrow=3)
kappa(A,exact=TRUE)
A
norm(A,type="F")*norm(solve(A),type="F")
sqrt(sum(c(A)^2))*sqrt(sum(c(solve(A))^2))
kappa(A)
browseVignettes("betr")
browseVignettes("pandaR")
getwd()
tools::showNonASCII(readLines("~/vignettes/pandaR.Rmd"))
tools::showNonASCII(readLines("vignettes/pandaR.Rmd"))
tools::showNonASCII(readLines("./vignettes/pandaR.Rmd"))
getwd()
tools::showNonASCII(readLines("./gd/Harvard/Research/R_Packages/pandaR/vignettes/pandaR.Rmd"))
tools::showNonASCII(readLines("./gd/Harvard/Research/R_Packages/pandaR/vignettes/pandaR.Rmd"))
library(pandaR)
data(pandaToyData)
```
\texttt{pandaToyData} is a list containing a regulatory structure derived from sequence motif analysis, protein-protein interaction data and a gene expression.
pandaResult <- panda(pandaToyData$motif, pandaToyData$expression, pandaToyData$ppi)
topNet <- topedges(pandaResult, 1000)
targetedGenes(topNet, c("AR"))
topSubnet <- subnetwork(topNet, c("AR","ARID3A","ELK1"))
plotGraph(topSubnet)
sessionInfo()
?plotGraph
class(topSubnet)
is.list(topSubnet)
library(pandaR)
data(pandaToyData)
pandaResult <- panda(pandaToyData$motif, pandaToyData$expression, pandaToyData$ppi)
pandaResult
install.packages("shiny")
library(shiny)
runExample("01_hello")
library(bereR)
?bereE
?bereR
?ldaBERE
library(bereR)
?ldaBERE
mean(c(.99,1/(99:1)))
mean(c(.99,1/(99:2)))
mean(c(1/(99:2)))
mean(c(.99,1/(100:2)))
library(pandaR)
library(bere)
library(reshape2)
version()
R.Version()
install.packages("reshape2")
install.packages(penalized)
install.packages('penalized')
install.packages('ROCR')
install.packages('ggplot2')
install.packages('dplyr')
source("http://bioconductor.org/biocLite.R")
biocLite("pandaR")
install.packages('XML')
install.packages('shiny')
install.packages("BiomaRt")
source("http://bioconductor.org/biocLite.R")
biocLite("biomaRt")
install.packages('neuralnet')
library("neuralnet")
?neuralnet
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
traininginput
trainingoutput
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
trainingdata
head(trainingdata)
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
plot(net.sqrt)
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
ls(net.results)
ls(net.results)
print(net.results$net.result)
cleanoutput <- cbind(testdata,sqrt(testdata),
as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
head(testdata)
library(MASS)
mvrnorm(n = 1, c(0,0), matrix(c(1,1,1,1),nrow=2), tol = 1e-6, empirical = FALSE, EISPACK = FALSE)
mvrnorm(n = 1, c(0,0), matrix(c(1,1,1,1),nrow=2), tol = 1e-6, empirical = FALSE, EISPACK = FALSE)
mvrnorm(n = 10, c(0,0), matrix(c(1,1,1,1),nrow=2), tol = 1e-6, empirical = FALSE, EISPACK = FALSE)
mvrnorm(n = 10, c(0,0), matrix(c(1,.5,1,.5),nrow=2), tol = 1e-6, empirical = FALSE, EISPACK = FALSE)
values <- mvrnorm(n = 10, c(0,0), matrix(c(1,.5,1,.5),nrow=2), tol = 1e-6, empirical = FALSE, EISPACK = FALSE)
qplot(values)
library(ggplot2)
qplot(values)
qplot(values[,1],values[,2])
values <- mvrnorm(n = 30, c(0,0), matrix(c(1,.5,1,.5),nrow=2), tol = 1e-6, empirical = FALSE, EISPACK = FALSE)
qplot(values[,1], values[,2])
values
values <- mvrnorm(n = 50, c(0,0), matrix(c(1,.5,1,.5),nrow=2), tol = 1e-6, empirical = FALSE, EISPACK = FALSE)
qplot(values[,1], values[,2])
?neuralnet
colnames(values) <- c("x","y")
qplot(values[,1], values[,2])
qplot(values$x, values$y)
values$x
values
head(values)
values$x
values <- data.frame(mvrnorm(n = 50, c(0,0), matrix(c(1,.5,1,.5),nrow=2), tol = 1e-6, empirical = FALSE, EISPACK = FALSE))
colnames(values) <- c("x","y")
qplot(values$x, values$y)
neuralnet(y~x, values, hidden=10, threshold=0.01)
corrNet <- neuralnet(y~x, values, hidden=10, threshold=0.01)
corrNet <- neuralnet(y~x, values, hidden=10, threshold=0.01)
plot(corrNet)
testdata
net.results <- compute(corrNet, rnorm(10)) #Run them through the neural network
net.results
validationset <- rnorm(10)
net.results <- compute(corrNet, validationset) #Run them through the neural network
net.results
qplot(validationset,net.results$net.result)
trainingVals <- rnorm(100)
trainingVals <- rnorm(100)
values <- data.frame(trainingVals=trainingVals, trainingVals^2+20)
values
colnames(values) <- c("x","y")
qplot(values$x, values$y)
corrNet <- neuralnet(y~x, values, hidden=10, threshold=0.01)
plot(corrNet)
validationset <- rnorm(100)
net.results <- compute(corrNet, validationset) #Run them through the neural network
qplot(validationset,net.results$net.result)
qplot(validationset, validationset^2+20)
qplot(validationset, net.results$net.result)
qplot(validationset, validationset^2+20)
qplot(validationset, net.results$net.result)
qplot(validationset, validationset^2+20)
trainingVals <- rnorm(100)
values <- data.frame(trainingVals=trainingVals, rnorm(100)+trainingVals^2+20)
colnames(values) <- c("x","y")
qplot(values$x, values$y)
corrNet <- neuralnet(y~x, values, hidden=10, threshold=0.01)
plot(corrNet)
validationset <- rnorm(100)
net.results <- compute(corrNet, validationset) #Run them through the neural network
qplot(validationset, net.results$net.result)
qplot(validationset, validationset^2+20)
qplot(validationset, net.results$net.result)
trainingVals <- rnorm(1000)
values <- data.frame(trainingVals=trainingVals, rnorm(1000)+trainingVals^2+20)
colnames(values) <- c("x","y")
qplot(values$x, values$y)
corrNet <- neuralnet(y~x, values, hidden=10, threshold=0.01)
plot(corrNet)
validationset <- rnorm(100)
net.results <- compute(corrNet, validationset) #Run them through the neural network
qplot(validationset, net.results$net.result)
qplot(validationset, validationset^2+20)
qplot(validationset, net.results$net.result)
qplot(values$x, values$y)
qplot(validationset, net.results$net.result)
qplot(validationset, validationset^2+20)
qplot(validationset, net.results$net.result)
trainingVals <- rnorm(1000)
values <- data.frame(trainingVals=trainingVals, rnorm(1000)+trainingVals^2+20)
colnames(values) <- c("x","y")
qplot(values$x, values$y)
corrNet <- neuralnet(y~x, values, hidden=1, threshold=0.01)
plot(corrNet)
validationset <- rnorm(100)
net.results <- compute(corrNet, validationset) #Run them through the neural network
qplot(validationset, net.results$net.result)
trainingVals <- rnorm(1000)
values <- data.frame(trainingVals=trainingVals, rnorm(1000)+trainingVals^2+20)
colnames(values) <- c("x","y")
qplot(values$x, values$y)
corrNet <- neuralnet(y~x, values, hidden=100, threshold=0.01)
trainingVals <- rnorm(1000)
values <- data.frame(trainingVals=trainingVals, rnorm(1000)+trainingVals^2+20)
colnames(values) <- c("x","y")
qplot(values$x, values$y)
corrNet <- neuralnet(y~x, values, hidden=2, threshold=0.01)
plot(corrNet)
validationset <- rnorm(100)
net.results <- compute(corrNet, validationset) #Run them through the neural network
qplot(validationset, net.results$net.result)
citation("pandaR")
A <- matrix(rnorm(20000*50),ncol=50)
B <- cor(A)
B <- cor(t(A))
install.packages('gputools')
library(panda)
library(pandaR)
?panda
data(pandaToyData)
pandaResult <- panda(pandaToyData$motif,
pandaToyData$expression)
top.net <- topedges(pandaResult, 1000)
top.subnet <- subnetwork(topNet,
c("AR","ARID3A","ELK1"))
topSubnet <- subnetwork(topNet,
c("AR","ARID3A","ELK1"))
topNet <- topedges(pandaResult, 1000)
topSubnet <- subnetwork(topNet,
c("AR","ARID3A","ELK1"))
library(igraph)
install.packages('igraph')
library(igraph)
plot(graph.incidence(top.net@reg.net),
layout=layout.bipartite)
plot(graph.incidence(topNet@reg.net),
layout=layout.bipartite)
slots(topNet)
names(topNet)
topNet
plot(graph.incidence(topSubnet),
layout=layout.bipartite)
library(gputools)
install.packages('gputools')
topSubnet <- subnetwork(topNet,
c("AR","ELK4","ELK1"))
plot(graph.incidence(topSubnet),
layout=layout.bipartite)
topSubnet <- subnetwork(topNet,
c("SWI6","BMP1","ELK1"))
topSubnet <- subnetwork(topNet,
c("SWI6","MBP1","ELK1"))
names(topNet)
dim(topNet)
topNet
topSubnet <- subnetwork(topNet,
c("AR","ELK4","ELK1"))
topSubnet <- subnetwork(topNet,
c("AR","ELK4","ADR1"))
topNet@regNet
colnames(topNet@regNet)
topNet@regNet%*%t(topNet@regNet)
dim(topNet@regNet%*%t(topNet@regNet))
topSubnet <- subnetwork(topNet,
c("AR","VDR","RXRA"))
plot(graph.incidence(topSubnet),
layout=layout.bipartite)
topSubnet <- subnetwork(topNet,
c("TLX1","VDR","RXRA"))
plot(graph.incidence(topSubnet),
layout=layout.bipartite)
topSubnet <- subnetwork(topNet,
c("TLX1","VDR","RXRA","PPARG"))
plot(graph.incidence(topSubnet),
layout=layout.bipartite)
topNet<-topedges(pandaResult, 1000)
topSubnet <- subnetwork(topNet,
c("TLX1","VDR","RXRA","PPARG"))
plot(graph.incidence(topSubnet),
layout=layout.bipartite)
topNet<-topedges(pandaResult, 100)
topSubnet <- subnetwork(topNet,
c("TLX1","VDR","RXRA","PPARG"))
plot(graph.incidence(topSubnet),
layout=layout.bipartite)
topNet<-topedges(pandaResult, 500)
topSubnet <- subnetwork(topNet,
c("TLX1","VDR","RXRA","PPARG"))
topSubnet <- subnetwork(topNet, c("TLX1","VDR","RXRA","PPARG"))
plot(graph.incidence(topSubnet),layout=layout.bipartite)
topNet<-topedges(pandaResult, 1000)
topSubnet <- subnetwork(topNet, c("TLX1","VDR","RXRA","PPARG"))
plot(graph.incidence(topSubnet),layout=layout.bipartite)
topNet<-topedges(pandaResult, 1000)
topSubnet <- subnetwork(topNet, c("TLX1","VDR","RXRA","PPARG"))
plot(graph.incidence(topSubnet),layout=layout.bipartite)
g <- graph.incidence(topSubnet)
V(g)
V(g)$name
transcriptionFactors <- c("TLX1","VDR","RXRA","PPARG")
topSubnet <- subnetwork(topNet, transcriptionFactors)
g <- graph.incidence(topSubnet)
plot(g,layout=layout.bipartite)
V(g)$name %in% transcriptionFactors
V(g)$name[-1:-4]
V(g)$name
V(g)$name[-1:-4]<-""
plot(g,layout=layout.bipartite)
list.files(pattern="output_20_")
library(data.table)
library(ggplot2)
library(gplots)
library(RColorBrewer)
library(cluster)
setwd("~/1000GP/")
V.list       <- lapply(file.path(, "all_V.csv"), read.csv, row.names=1)
list.files(pattern="output_20_")
cumulativeFiles <- list.files(pattern="output_20_")
cumulativeFiles <- list.files(pattern="output_20_")[1:2]
.list       <- lapply(file.path(cumulativeFiles, "all_V.csv"), read.csv, row.names=1)
U.list       <- lapply(file.path(cumulativeFiles, "all_U.csv"), read.csv, row.names=1)
V.list       <- lapply(V.list, as.matrix)
U.list       <- lapply(U.list, as.matrix)
alleleMax <- as.numeric(sub("output_20_","",file.path(list.files(pattern="output_20_"))))
names(V.list) <- alleleMax
names(U.list) <- alleleMax
V.list <- V.list[as.character(sort(alleleMax))]
U.list <- U.list[as.character(sort(alleleMax))]
U.interval.list <- lapply(2:length(U.list), function(index){
U.list[[index]]-U.list[[index-1]]
})
V.interval.list <- lapply(2:length(V.list), function(index){
V.list[[index]]-V.list[[index-1]]
})
names(U.interval.list) <- paste(names(V.list)[-length(V.list)],names(V.list)[-1],sep='-')
names(V.interval.list) <- paste(names(V.list)[-length(V.list)],names(V.list)[-1],sep='-')
U.interval.list[["20-50"]] <- U.list[["50"]]
V.interval.list[["20-50"]] <- V.list[["50"]]
# Read in the U's and V's that were gathered in an interval
interval.file.list <- list.files(pattern="output")[!grepl("_20_",list.files(pattern="output"))][1:3]
V.list2       <- lapply(file.path(interval.file.list, "all_V.csv"), read.csv, row.names=1)
U.list2       <- lapply(file.path(interval.file.list, "all_U.csv"), read.csv, row.names=1)
